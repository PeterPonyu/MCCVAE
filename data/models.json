{
  "models": [
    {
      "id": 1,
      "abbreviation": "scGPCL",
      "full_name": "Single-cell Graph Prototypical Contrastive Learning",
      "publication_year": 2023,
      "authors": "Junseok Lee, et al.",
      "brief_description": "A graph-based contrastive learning approach using prototypical representations for cell type identification in scRNA-seq data.",
      "paper_title": "scGPCL: graph prototypical contrastive learning for single-cell RNA-seq clustering",
      "journal": "Bioinformatics",
      "methodology": ["Graph Neural Network", "Prototypical Contrastive Learning", "ZINB"],
      "github_url": "https://github.com/Junseok0207/scGPCL",
      "doi": "10.1093/bioinformatics/btad342",
      "category": "Contrastive Learning",
      "features": ["Prototype-based learning", "Instance and prototype contrastive", "ZINB reconstruction"]
    },
    {
      "id": 2,
      "abbreviation": "scHSC",
      "full_name": "Single-cell Hard Sample Contrastive Learning",
      "publication_year": 2025,
      "authors": "Sheng Fang, Xiaokang Yu, et al.",
      "brief_description": "A contrastive learning framework that focuses on hard sample mining with ZINB-based loss for improved scRNA-seq clustering performance.",
      "paper_title": "scHSC: enhancing single-cell RNA-seq clustering via hard sample contrastive learning",
      "journal": "Briefings in Bioinformatics",
      "methodology": ["Hard Sample Contrastive Learning", "ZINB Loss", "Pseudo-labeling"],
      "github_url": "https://github.com/fangs25/scHSC",
      "doi": "10.1093/bib/bbaf485",
      "category": "Contrastive Learning",
      "features": ["Hard sample mining", "Pseudo-labeling", "ZINB reconstruction"]
    },
    {
      "id": 3,
      "abbreviation": "scDiffusion",
      "full_name": "Single-cell Diffusion Model",
      "publication_year": 2024,
      "authors": "Eper Luo, et al.",
      "brief_description": "A latent diffusion model combined with VAE for generating realistic single-cell gene expression data and data augmentation.",
      "paper_title": "scDiffusion: conditional generation of high-quality single-cell data using diffusion model",
      "journal": "Bioinformatics",
      "methodology": ["Latent Diffusion Model", "Variational Autoencoder", "Denoising"],
      "github_url": "https://github.com/EperLuo/scDiffusion",
      "doi": "10.1093/bioinformatics/btae518",
      "category": "Diffusion Model",
      "features": ["Data generation", "Conditional generation", "Classifier-free guidance"]
    },
    {
      "id": 4,
      "abbreviation": "SCALEX",
      "full_name": "Single-cell data integration with Variational Autoencoder",
      "publication_year": 2022,
      "authors": "Lei Xiong, et al.",
      "brief_description": "A VAE-based method for integrating heterogeneous scRNA-seq datasets across batches while preserving biological variation.",
      "paper_title": "Online single-cell data integration through projecting heterogeneous datasets into a common cell-embedding space",
      "journal": "Nature Communications",
      "methodology": ["Variational Autoencoder", "Batch Integration", "Domain-Specific BatchNorm"],
      "github_url": "https://github.com/jsxlei/SCALEX",
      "doi": "10.1038/s41467-022-33758-z",
      "category": "Variational Autoencoder",
      "features": ["Cross-batch integration", "Domain-specific normalization", "Online learning"]
    },
    {
      "id": 5,
      "abbreviation": "Cell BLAST",
      "full_name": "Cell Basic Local Alignment Search Tool",
      "publication_year": 2020,
      "authors": "Zhi-Jie Cao, et al.",
      "brief_description": "A neural network-based cell querying method using VAE for unbiased cell embedding, enabling efficient annotation and identification of novel cell types.",
      "paper_title": "Searching large-scale scRNA-seq databases via unbiased cell embedding with Cell BLAST",
      "journal": "Nature Communications",
      "methodology": ["Variational Autoencoder", "Cell-to-cell Similarity", "DIRECTi"],
      "github_url": "https://github.com/gao-lab/Cell_BLAST",
      "doi": "10.1038/s41467-020-17281-7",
      "category": "Variational Autoencoder",
      "features": ["Cell annotation", "Database querying", "ZINB/NB reconstruction"]
    },
    {
      "id": 6,
      "abbreviation": "GM-VAE",
      "full_name": "Geometric Manifold Variational Autoencoder",
      "publication_year": 2025,
      "authors": "Mehdi Joodaki, et al.",
      "brief_description": "A GM-VAE framework supporting multiple geometric distributions (Euclidean, Poincaré, PGM, LearnablePGM, HW) for patient-level analysis of single-cell disease atlases. See GM-VAE-LPGM, GM-VAE-PGM, GM-VAE-HW, GM-VAE-Poincaré for specific variants.",
      "paper_title": "PILOT-GM-VAE: patient-level analysis of single-cell disease atlas with optimal transport of Gaussian mixture variational autoencoders",
      "journal": "Briefings in Bioinformatics",
      "methodology": ["Gaussian Mixture VAE", "Optimal Transport", "Hyperbolic Geometry"],
      "github_url": "https://github.com/CostaLab/PILOT-GM-VAE",
      "doi": "10.1093/bib/bbaf547",
      "category": "Variational Autoencoder",
      "features": ["Geometric distributions", "Poincaré space", "Hyperboloid space", "4 variants: LPGM, PGM, HW, Poincaré"]
    },
    {
      "id": 7,
      "abbreviation": "scGNN",
      "full_name": "Single-cell Graph Neural Network",
      "publication_year": 2021,
      "authors": "Juexin Wang, et al.",
      "brief_description": "A graph neural network framework that formulates relationships between cells using cell-cell graphs and leverages autoencoders with LTMG for imputation and clustering.",
      "paper_title": "scGNN is a novel graph neural network framework for single-cell RNA-Seq analyses",
      "journal": "Nature Communications",
      "methodology": ["Graph Neural Network", "Autoencoder", "kNN Graph"],
      "github_url": "https://github.com/juexinwang/scGNN",
      "doi": "10.1038/s41467-021-22197-x",
      "category": "Graph Neural Network",
      "features": ["Cell-cell graph", "Imputation", "Inner product decoder"]
    },
    {
      "id": 8,
      "abbreviation": "scDeepCluster",
      "full_name": "Single-cell Deep Clustering",
      "publication_year": 2019,
      "authors": "Tian Tian, et al.",
      "brief_description": "A deep learning approach combining autoencoders with DEC-style clustering for unsupervised cell type identification in scRNA-seq data.",
      "paper_title": "Clustering single-cell RNA-seq data with a model-based deep learning approach",
      "journal": "Nature Machine Intelligence",
      "methodology": ["Autoencoder", "Deep Embedded Clustering", "ZINB"],
      "github_url": "https://github.com/ttgump/scDeepCluster",
      "doi": "10.1038/s42256-019-0037-0",
      "category": "Clustering",
      "features": ["DEC-style clustering", "Multi-stage training", "KMeans initialization"]
    },
    {
      "id": 9,
      "abbreviation": "scDHMap",
      "full_name": "Single-cell Deep Hyperbolic Mapping",
      "publication_year": 2023,
      "authors": "Tian Tian, et al.",
      "brief_description": "A hyperbolic VAE that embeds scRNA-seq data in Poincaré space to preserve hierarchical cell relationships for visualization and analysis.",
      "paper_title": "scDHMap: hyperbolic variational autoencoder for single-cell transcriptomics embedding",
      "journal": "Genome Research",
      "methodology": ["Hyperbolic VAE", "Lorentz Hyperboloid", "t-SNE Repulsion"],
      "github_url": "https://github.com/ttgump/scDHMap",
      "doi": "10.1101/gr.277068.122",
      "category": "Variational Autoencoder",
      "features": ["Hyperbolic space", "Poincaré ball interface", "Hierarchical preservation"]
    },
    {
      "id": 10,
      "abbreviation": "scGCC",
      "full_name": "Single-cell Graph Contrastive Clustering",
      "publication_year": 2023,
      "authors": "Tian SW, Ni JC, et al.",
      "brief_description": "A graph contrastive clustering framework using graph attention networks with neighborhood augmentations for scRNA-seq data analysis.",
      "paper_title": "scGCC: Graph Contrastive Clustering With Neighborhood Augmentations for scRNA-Seq Data Analysis",
      "journal": "IEEE Journal of Biomedical and Health Informatics",
      "methodology": ["Graph Attention Network", "MoCo-style Contrastive Learning", "kNN Graph"],
      "doi": "10.1109/JBHI.2023.3319551",
      "category": "Contrastive Learning",
      "features": ["GAT encoder", "MoCo framework", "Neighborhood augmentation"]
    },
    {
      "id": 11,
      "abbreviation": "CLEAR",
      "full_name": "Contrastive LEArning framework for scRNA-seq",
      "publication_year": 2022,
      "authors": "Wenkai Han, Yuqi Cheng, et al.",
      "brief_description": "A self-supervised contrastive learning framework for scRNA-seq data representation that handles batch effects and dropout events simultaneously.",
      "paper_title": "Self-supervised contrastive learning for integrative single cell RNA-seq data analysis",
      "journal": "Briefings in Bioinformatics",
      "methodology": ["Self-supervised Contrastive Learning", "MoCo", "MLP Encoder"],
      "github_url": "https://github.com/run-yu/CLEAR",
      "doi": "10.1093/bib/bbac377",
      "category": "Contrastive Learning",
      "features": ["MoCo-style training", "Batch effect handling", "Dropout robustness"]
    },
    {
      "id": 12,
      "abbreviation": "PCA",
      "full_name": "Principal Component Analysis",
      "publication_year": 1901,
      "authors": "Karl Pearson",
      "brief_description": "A linear dimensionality reduction technique that identifies orthogonal principal components maximizing variance in the data. Widely used for preprocessing and visualization in single-cell analysis.",
      "paper_title": "On Lines and Planes of Closest Fit to Systems of Points in Space",
      "journal": "Philosophical Magazine",
      "methodology": ["Linear Transformation", "Eigenvalue Decomposition", "SVD"],
      "github_url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html",
      "doi": "10.1080/14786440109462720",
      "category": "Classical Machine Learning",
      "features": ["Linear dimensionality reduction", "Variance maximization", "Orthogonal components", "Fast computation"]
    },
    {
      "id": 13,
      "abbreviation": "ICA",
      "full_name": "Independent Component Analysis",
      "publication_year": 1994,
      "authors": "Pierre Comon",
      "brief_description": "A computational method for separating multivariate signals into statistically independent non-Gaussian components. Used in single-cell analysis to identify independent sources of variation.",
      "paper_title": "Independent component analysis, A new concept?",
      "journal": "Signal Processing",
      "methodology": ["Blind Source Separation", "Non-Gaussianity Maximization", "FastICA"],
      "github_url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html",
      "doi": "10.1016/0165-1684(94)90029-9",
      "category": "Classical Machine Learning",
      "features": ["Statistical independence", "Non-Gaussian signal separation", "Blind source separation", "Negentropy optimization"]
    },
    {
      "id": 14,
      "abbreviation": "FA",
      "full_name": "Factor Analysis",
      "publication_year": 1904,
      "authors": "Charles Spearman",
      "brief_description": "A statistical method identifying latent factors that explain correlations among observed variables. Models data as linear combinations of latent factors plus noise, useful for identifying gene modules.",
      "paper_title": "General Intelligence, Objectively Determined and Measured",
      "journal": "American Journal of Psychology",
      "methodology": ["Latent Variable Model", "Maximum Likelihood", "EM Algorithm"],
      "github_url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FactorAnalysis.html",
      "doi": "10.2307/1412107",
      "category": "Classical Machine Learning",
      "features": ["Latent factor identification", "Noise modeling", "Heteroscedastic variance", "Interpretable loadings"]
    },
    {
      "id": 15,
      "abbreviation": "NMF",
      "full_name": "Non-negative Matrix Factorization",
      "publication_year": 1999,
      "authors": "Daniel D. Lee, H. Sebastian Seung",
      "brief_description": "A matrix factorization technique constraining both factors to be non-negative, producing parts-based representations. Ideal for gene expression data where negative values are not meaningful.",
      "paper_title": "Learning the parts of objects by non-negative matrix factorization",
      "journal": "Nature",
      "methodology": ["Matrix Factorization", "Non-negativity Constraints", "Multiplicative Updates"],
      "github_url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html",
      "doi": "10.1038/44565",
      "category": "Classical Machine Learning",
      "features": ["Parts-based representation", "Non-negative constraints", "Additive components", "Interpretable factors"]
    },
    {
      "id": 16,
      "abbreviation": "KPCA",
      "full_name": "Kernel Principal Component Analysis",
      "publication_year": 1997,
      "authors": "Bernhard Schölkopf, Alexander Smola, Klaus-Robert Müller",
      "brief_description": "A non-linear extension of PCA using kernel methods to project data into higher-dimensional feature spaces, capturing non-linear relationships in single-cell data.",
      "paper_title": "Kernel principal component analysis",
      "journal": "International Conference on Artificial Neural Networks",
      "methodology": ["Kernel Methods", "Non-linear Mapping", "Eigenvalue Decomposition"],
      "github_url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html",
      "doi": "10.1007/BFb0020217",
      "category": "Classical Machine Learning",
      "features": ["Non-linear dimensionality reduction", "Kernel trick", "RBF/Polynomial kernels", "Manifold learning"]
    },
    {
      "id": 17,
      "abbreviation": "TSVD",
      "full_name": "Truncated Singular Value Decomposition",
      "publication_year": 1965,
      "authors": "Gene H. Golub, William Kahan",
      "brief_description": "A matrix decomposition technique computing only the k largest singular values, efficient for large sparse matrices. Forms the basis of LSI/LSA and is commonly used for scRNA-seq preprocessing.",
      "paper_title": "Calculating the Singular Values and Pseudo-Inverse of a Matrix",
      "journal": "SIAM Journal on Numerical Analysis",
      "methodology": ["Matrix Decomposition", "Singular Value Decomposition", "Low-rank Approximation"],
      "github_url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html",
      "doi": "10.1137/0702016",
      "category": "Classical Machine Learning",
      "features": ["Sparse matrix support", "Low-rank approximation", "Memory efficient", "No centering required"]
    },
    {
      "id": 18,
      "abbreviation": "DICL",
      "full_name": "Dictionary Learning",
      "publication_year": 2009,
      "authors": "Julien Mairal, Francis Bach, Jean Ponce, Guillermo Sapiro",
      "brief_description": "A representation learning method that learns a dictionary of basis elements and sparse codes. Produces interpretable sparse representations of single-cell gene expression patterns.",
      "paper_title": "Online Dictionary Learning for Sparse Coding",
      "journal": "International Conference on Machine Learning",
      "methodology": ["Sparse Coding", "Dictionary Learning", "Online Optimization"],
      "github_url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.DictionaryLearning.html",
      "doi": "10.1145/1553374.1553463",
      "category": "Classical Machine Learning",
      "features": ["Sparse representations", "Learned dictionary", "Online learning", "Interpretable atoms"]
    },
    {
      "id": 19,
      "abbreviation": "LSI",
      "full_name": "Latent Semantic Indexing",
      "publication_year": 1990,
      "authors": "Scott Deerwester, Susan Dumais, George Furnas, Thomas Landauer, Richard Harshman",
      "brief_description": "A dimensionality reduction technique using SVD on TF-IDF weighted matrices. Adapted for scATAC-seq analysis to reduce chromatin accessibility data while preserving biological signal.",
      "paper_title": "Indexing by Latent Semantic Analysis",
      "journal": "Journal of the American Society for Information Science",
      "methodology": ["TF-IDF Weighting", "Singular Value Decomposition", "Low-rank Approximation"],
      "github_url": "https://satijalab.org/signac/",
      "doi": "10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9",
      "category": "ATAC-specific Methods",
      "features": ["TF-IDF normalization", "Handles sparse binary data", "Removes batch effects", "Standard scATAC-seq preprocessing"]
    },
    {
      "id": 20,
      "abbreviation": "PeakVI",
      "full_name": "Peak Variational Inference",
      "publication_year": 2021,
      "authors": "Tal Ashuach, Daniel A. Reidenbach, Nir Yosef",
      "brief_description": "A deep generative model for scATAC-seq data using variational inference with Bernoulli likelihood. Learns cell embeddings while accounting for cell-specific and region-specific technical effects.",
      "paper_title": "PeakVI: A Deep Generative Model For Single Cell Chromatin Accessibility Analysis",
      "journal": "BioRxiv",
      "methodology": ["Variational Autoencoder", "Bernoulli Likelihood", "Neural Network Decoder"],
      "github_url": "https://docs.scvi-tools.org/en/stable/user_guide/models/peakvi.html",
      "doi": "10.1101/2021.04.29.442020",
      "category": "ATAC-specific Methods",
      "features": ["Cell and region scaling factors", "Batch correction", "GPU accelerated", "Differential accessibility"]
    },
    {
      "id": 21,
      "abbreviation": "PoissonVI",
      "full_name": "Poisson Variational Inference",
      "publication_year": 2023,
      "authors": "scvi-tools development team",
      "brief_description": "A variational autoencoder for scATAC-seq fragment count data using Poisson likelihood. Designed for quantitative chromatin accessibility analysis with proper count-based modeling.",
      "paper_title": "PoissonVI: Analyzing quantitative scATAC-seq fragment counts",
      "journal": "scvi-tools",
      "methodology": ["Variational Autoencoder", "Poisson Likelihood", "Fragment Count Modeling"],
      "github_url": "https://docs.scvi-tools.org/en/stable/user_guide/models/poissonvi.html",
      "doi": "N/A",
      "category": "ATAC-specific Methods",
      "features": ["Quantitative ATAC analysis", "Fragment count modeling", "Poisson distribution", "scvi-tools integration"]
    },
    {
      "id": 22,
      "abbreviation": "β-VAE",
      "full_name": "Beta Variational Autoencoder",
      "publication_year": 2017,
      "authors": "Irina Higgins, Loic Matthey, Arka Pal, et al.",
      "brief_description": "A modification of VAE that introduces an adjustable hyperparameter β to balance latent channel capacity and independence constraints with reconstruction accuracy, enabling learning of disentangled representations.",
      "paper_title": "beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework",
      "journal": "ICLR",
      "methodology": ["Variational Autoencoder", "KL Divergence Weighting", "Disentanglement"],
      "github_url": "https://github.com/1Konny/Beta-VAE",
      "doi": "N/A",
      "category": "VAE Regularization",
      "features": ["Disentangled representations", "Adjustable β hyperparameter", "Interpretable latent factors", "Rate-distortion tradeoff"]
    },
    {
      "id": 23,
      "abbreviation": "DIP-VAE",
      "full_name": "Disentangled Inferred Prior VAE",
      "publication_year": 2018,
      "authors": "Abhishek Kumar, Prasanna Sattigeri, Avinash Balakrishnan",
      "brief_description": "A VAE variant that encourages disentanglement by regularizing the expectation of the approximate posterior to match a factorized prior, improving upon β-VAE with better reconstruction quality.",
      "paper_title": "Variational Inference of Disentangled Latent Concepts from Unlabeled Observations",
      "journal": "ICLR",
      "methodology": ["Variational Autoencoder", "Covariance Regularization", "Disentanglement"],
      "github_url": "https://github.com/IBM/AIX360",
      "doi": "10.48550/arXiv.1711.00848",
      "category": "VAE Regularization",
      "features": ["Inferred prior matching", "Covariance matrix regularization", "DIP-I and DIP-II variants", "Improved disentanglement metric"]
    },
    {
      "id": 24,
      "abbreviation": "InfoVAE",
      "full_name": "Information Maximizing VAE",
      "publication_year": 2017,
      "authors": "Shengjia Zhao, Jiaming Song, Stefano Ermon",
      "brief_description": "A class of VAE objectives that maximize mutual information between latent variables and data, mitigating posterior collapse and improving latent feature utilization regardless of decoder flexibility.",
      "paper_title": "InfoVAE: Information Maximizing Variational Autoencoders",
      "journal": "AAAI",
      "methodology": ["Variational Autoencoder", "MMD Regularization", "Mutual Information Maximization"],
      "github_url": "https://github.com/ShengjiaZhao/InfoVAE",
      "doi": "10.48550/arXiv.1706.02262",
      "category": "VAE Regularization",
      "features": ["MMD divergence", "Prevents posterior collapse", "Flexible decoder compatibility", "Information-theoretic objective"]
    },
    {
      "id": 25,
      "abbreviation": "TC-VAE",
      "full_name": "Total Correlation VAE (FactorVAE)",
      "publication_year": 2018,
      "authors": "Hyunjik Kim, Andriy Mnih",
      "brief_description": "A VAE that explicitly penalizes the total correlation in the latent distribution, encouraging factorial (statistically independent) representations with a better disentanglement-reconstruction tradeoff than β-VAE.",
      "paper_title": "Disentangling by Factorising",
      "journal": "ICML",
      "methodology": ["Variational Autoencoder", "Total Correlation Penalty", "Density Ratio Estimation"],
      "github_url": "https://github.com/1Konny/FactorVAE",
      "doi": "10.48550/arXiv.1802.05983",
      "category": "VAE Regularization",
      "features": ["Total correlation decomposition", "Factorial latent distribution", "Discriminator-based estimation", "Improved disentanglement metric"]
    },
    {
      "id": 26,
      "abbreviation": "GM-VAE-LPGM",
      "full_name": "Learnable Product of Gaussian Mixture VAE",
      "publication_year": 2025,
      "authors": "Mehdi Joodaki, et al. (PILOT-GM-VAE)",
      "brief_description": "A GM-VAE variant using learnable product of Gaussian mixtures in Euclidean space, allowing adaptive geometric structure learning for patient-level single-cell analysis.",
      "paper_title": "PILOT-GM-VAE: patient-level analysis with Gaussian mixture VAE",
      "journal": "Briefings in Bioinformatics",
      "methodology": ["Gaussian Mixture VAE", "Learnable Geometry", "Optimal Transport"],
      "github_url": "https://github.com/CostaLab/PILOT-GM-VAE",
      "doi": "10.1093/bib/bbaf547",
      "category": "Geometric VAE",
      "features": ["Learnable product structure", "Euclidean geometry", "Patient-level analysis", "Adaptive manifold learning"]
    },
    {
      "id": 27,
      "abbreviation": "GM-VAE-PGM",
      "full_name": "Product of Gaussian Mixture VAE",
      "publication_year": 2025,
      "authors": "Mehdi Joodaki, et al. (PILOT-GM-VAE)",
      "brief_description": "A GM-VAE variant with fixed product of Gaussian mixture structure, providing stable geometric representations for multi-sample single-cell disease atlas analysis.",
      "paper_title": "PILOT-GM-VAE: patient-level analysis with Gaussian mixture VAE",
      "journal": "Briefings in Bioinformatics",
      "methodology": ["Gaussian Mixture VAE", "Fixed Product Structure", "Optimal Transport"],
      "github_url": "https://github.com/CostaLab/PILOT-GM-VAE",
      "doi": "10.1093/bib/bbaf547",
      "category": "Geometric VAE",
      "features": ["Fixed product structure", "Euclidean geometry", "Disease state comparison", "Stable training"]
    },
    {
      "id": 28,
      "abbreviation": "GM-VAE-HW",
      "full_name": "Hyperboloid Wrapped Gaussian Mixture VAE",
      "publication_year": 2025,
      "authors": "Mehdi Joodaki, et al. (PILOT-GM-VAE)",
      "brief_description": "A GM-VAE variant embedding cells in Lorentz hyperboloid space using wrapped Gaussian distributions, naturally capturing hierarchical cell type relationships.",
      "paper_title": "PILOT-GM-VAE: patient-level analysis with Gaussian mixture VAE",
      "journal": "Briefings in Bioinformatics",
      "methodology": ["Gaussian Mixture VAE", "Hyperboloid Geometry", "Wrapped Normal Distribution"],
      "github_url": "https://github.com/CostaLab/PILOT-GM-VAE",
      "doi": "10.1093/bib/bbaf547",
      "category": "Geometric VAE",
      "features": ["Lorentz hyperboloid space", "Wrapped Gaussian", "Hierarchical preservation", "Non-Euclidean geometry"]
    },
    {
      "id": 29,
      "abbreviation": "GM-VAE-Poincaré",
      "full_name": "Poincaré Ball Gaussian Mixture VAE",
      "publication_year": 2025,
      "authors": "Mehdi Joodaki, et al. (PILOT-GM-VAE)",
      "brief_description": "A GM-VAE variant operating in Poincaré ball hyperbolic space, ideal for representing tree-like cell differentiation hierarchies with exponentially growing capacity.",
      "paper_title": "PILOT-GM-VAE: patient-level analysis with Gaussian mixture VAE",
      "journal": "Briefings in Bioinformatics",
      "methodology": ["Gaussian Mixture VAE", "Poincaré Ball", "Hyperbolic Geometry"],
      "github_url": "https://github.com/CostaLab/PILOT-GM-VAE",
      "doi": "10.1093/bib/bbaf547",
      "category": "Geometric VAE",
      "features": ["Poincaré ball model", "Hyperbolic distance", "Tree-like hierarchy", "Exponential volume growth"]
    }
  ],
  "categories": [
    {
      "name": "Variational Autoencoder",
      "description": "Models based on VAE architecture for learning latent representations",
      "count": 4
    },
    {
      "name": "VAE Regularization",
      "description": "VAE variants with specialized regularization for disentanglement (β-VAE, DIP-VAE, InfoVAE, TC-VAE)",
      "count": 4
    },
    {
      "name": "Geometric VAE",
      "description": "VAE models using non-Euclidean and geometric manifold representations (GM-VAE variants: LPGM, PGM, HW, Poincaré)",
      "count": 4
    },
    {
      "name": "Contrastive Learning",
      "description": "Models using contrastive learning objectives for representation learning",
      "count": 4
    },
    {
      "name": "Graph Neural Network",
      "description": "Models leveraging graph structures for cell relationship modeling",
      "count": 1
    },
    {
      "name": "Clustering",
      "description": "Models focused on unsupervised clustering of single cells",
      "count": 1
    },
    {
      "name": "Diffusion Model",
      "description": "Models using diffusion-based generative approaches",
      "count": 1
    },
    {
      "name": "Classical Machine Learning",
      "description": "Traditional dimensionality reduction and matrix factorization methods",
      "count": 7
    },
    {
      "name": "ATAC-specific Methods",
      "description": "Methods specifically designed for scATAC-seq chromatin accessibility data",
      "count": 3
    }
  ],
  "total": 29
}
